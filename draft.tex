

\documentclass[12pt, titlepage, reqno]{article}


\title{Deep learning architectures in speech processing}

\begin{document}
\maketitle 


\section{Outline}
\begin{enumerate}
	%From Dafydd's mail Aug 21, 2016 at 12:21 PM
	\item A (very) brief overview of 'black box' and 'white/glass box' methods would be needed, starting with the old 'statistical vs. rule-based' fight. We can pool ideas about this
	\item If possible we should have some kind of working demos to illustrate what we are concerned with.
	\item A conclusion could contain something like tasks which are ideal for DNN etc. and tasks which are out of its scope."
\end{enumerate}
	% From Dafydd's mail Aug 21, 2016 at 12:21 PM 
\begin{verbatim} 
What is ML?
What is rule-based learning (i.e. generalisation, 
subsumption, automaton learning)?
What is statistical learning?
What is "training"?
What is the difference between supervised and unsupervised learning?
What is the difference between classification and sequence learning?
What are NNs/ANNs?
What are DNNs and what is the essential literature on them?
How do they relate to ML?
How are DNNs developed and evaluated in practice?
Where can working demos of DNNs be found?
Who does ML and who does DNNs?
What are the results of ML and DNNs in comparable tasks?
How do ML and DNN relate to current topics such as big data, 
surveillance, chess-playing, etc.?
What kind of insights can ML and DNN provide for linguists?
How do DNNs relate to first language acquisition and foreign 
language learning? \end{verbatim}
\end{document}